{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7ibhmaYD4E4xy5bJWlBaG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyna478/p1/blob/main/Diff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNUR6Q_54IrK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ks_2samp, chi2_contingency, entropy, wasserstein_distance\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score, mean_squared_error, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import datetime\n",
        "import warnings\n",
        "import re  # Ajoutez cette ligne\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ks_2samp, chi2_contingency, entropy, wasserstein_distance\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mutual_info_score, mean_squared_error, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Pour torch et les fonctionnalités de diffusion\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Pour le traitement des données\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "# Pour les métriques d'évaluation supplémentaires\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Pour la visualisation des distributions\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Pour les calculs statistiques\n",
        "from scipy import stats\n",
        "\n",
        "# Pour le parallélisme (optionnel, mais peut accélérer certains calculs)\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Pour la manipulation de dates (si vous avez des données temporelles)\n",
        "import datetime\n",
        "\n",
        "# Pour la gestion des avertissements\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedDiffusionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim=128, time_dim=128, seq_length=10,\n",
        "                 num_layers=4, num_heads=8, num_numeric_features=0,\n",
        "                 alphas_cumprod=None, alphas=None, betas=None, num_classes=1000,\n",
        "                 feature_types=None, feature_dims=None, feature_specific_params=None,\n",
        "                 dynamic_thresholding_ratio=0.995, interval_min=-1, interval_max=1):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.time_dim = time_dim\n",
        "        self.seq_length = seq_length\n",
        "        self.num_numeric_features = num_numeric_features\n",
        "        self.num_classes = num_classes\n",
        "        self.feature_types = feature_types or ['continuous'] * input_dim\n",
        "        self.feature_dims = feature_dims or [1] * input_dim\n",
        "        assert len(self.feature_types) == len(self.feature_dims), \"feature_types and feature_dims must have the same length\"\n",
        "        assert sum(self.feature_dims) == input_dim, f\"Sum of feature_dims ({sum(self.feature_dims)}) must equal input_dim ({input_dim})\"\n",
        "\n",
        "        self.dynamic_thresholding_ratio = dynamic_thresholding_ratio\n",
        "        self.interval_min = interval_min\n",
        "        self.interval_max = interval_max\n",
        "        self.dynamic_thresholding_ratio = 0.995\n",
        "\n",
        "         # Paramètres par défaut\n",
        "        self.default_interval_min = interval_min\n",
        "        self.default_interval_max = interval_max\n",
        "        self.default_dynamic_thresholding_ratio = dynamic_thresholding_ratio\n",
        "\n",
        "        # Paramètres spécifiques aux caractéristiques\n",
        "        self.feature_specific_params = feature_specific_params or {}\n",
        "\n",
        "        # Register buffers\n",
        "        if alphas_cumprod is not None:\n",
        "            self.register_buffer('alphas_cumprod', torch.tensor(alphas_cumprod, dtype=torch.float32))\n",
        "        if alphas is not None:\n",
        "            self.register_buffer('alphas', torch.tensor(alphas, dtype=torch.float32))\n",
        "        if betas is not None:\n",
        "            self.register_buffer('betas', torch.tensor(betas, dtype=torch.float32))\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_dim),\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "            nn.Mish(),\n",
        "            nn.LayerNorm(time_dim),\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "        )\n",
        "\n",
        "        self.input_upscale = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Mish()\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(hidden_dim + time_dim, hidden_dim),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.Mish(),\n",
        "                ResidualBlock(hidden_dim)\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.attention_layers = nn.ModuleList([\n",
        "            AttentionLayer(hidden_dim, num_heads=num_heads)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.class_embedding = nn.Embedding(num_classes + 1, hidden_dim)\n",
        "\n",
        "\n",
        "        print(f\"Model initialized with input_dim: {input_dim}, output_dim: {output_dim}\")\n",
        "        print(f\"Feature types: {feature_types}\")\n",
        "        print(f\"Feature dimensions: {feature_dims}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, t, c=None):\n",
        "        if isinstance(x, tuple):\n",
        "            x_cont, x_disc = x\n",
        "            print(f\"Forward input - cont shape: {x_cont.shape}, disc shape: {x_disc.shape}\")\n",
        "            x = torch.cat([x_cont, x_disc], dim=-1)\n",
        "\n",
        "        #print(f\"Forward method input shapes - x: {x.shape}, t: {t.shape}\")\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Time embedding\n",
        "        t_emb = self.time_mlp(t)\n",
        "        t_emb = t_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Process input\n",
        "        x = self.input_upscale(x)\n",
        "        x, _ = self.rnn(x)\n",
        "\n",
        "        # Apply layers with attention\n",
        "        for layer, attention in zip(self.layers, self.attention_layers):\n",
        "            x = layer(torch.cat([x, t_emb], dim=-1))\n",
        "            x = attention(x)\n",
        "\n",
        "        if c is None:\n",
        "            c = torch.full((x.shape[0],), self.num_classes, device=x.device)\n",
        "        else:\n",
        "            c = torch.where(c == -1, self.num_classes, c)\n",
        "\n",
        "        if c.dim() == 1:\n",
        "            c = c.unsqueeze(1).expand(-1, x.size(1))\n",
        "\n",
        "        class_emb = self.class_embedding(c)\n",
        "        x = x + class_emb\n",
        "\n",
        "        output = self.output_layer(x)\n",
        "        output_cont = output[:, :, :self.num_numeric_features]\n",
        "        output_disc = output[:, :, self.num_numeric_features:]\n",
        "\n",
        "        # Appliquer le limited interval et le dynamic thresholding spécifique à chaque caractéristique\n",
        "        for i in range(self.num_numeric_features):\n",
        "            feature = f\"numeric_{i}\"\n",
        "            params = self.feature_specific_params.get(feature, {})\n",
        "            interval_min = params.get('interval_min', self.default_interval_min)\n",
        "            interval_max = params.get('interval_max', self.default_interval_max)\n",
        "            dt_ratio = params.get('dynamic_thresholding_ratio', self.default_dynamic_thresholding_ratio)\n",
        "\n",
        "            # Utiliser des opérations qui créent de nouveaux tenseurs\n",
        "            output_cont_i = torch.clamp(output_cont[:, :, i:i+1], interval_min, interval_max)\n",
        "            output_cont_i = self.dynamic_thresholding(output_cont_i, dt_ratio)\n",
        "            output_cont = torch.cat([output_cont[:, :, :i], output_cont_i, output_cont[:, :, i+1:]], dim=2)\n",
        "\n",
        "\n",
        "        # Appliquer le limited interval aux sorties continues\n",
        "        output_cont = torch.clamp(output_cont, self.interval_min, self.interval_max)\n",
        "\n",
        "        # Appliquer le dynamic thresholding aux sorties continues\n",
        "        output_cont = self.dynamic_thresholding(output_cont, self.dynamic_thresholding_ratio)\n",
        "\n",
        "        # Traitement des sorties discrètes\n",
        "        output_disc_list = []\n",
        "        start_idx = 0\n",
        "        for feat_dim in self.feature_dims[self.num_numeric_features:]:\n",
        "            end_idx = start_idx + feat_dim\n",
        "            feat_output = output_disc[:, :, start_idx:end_idx]\n",
        "            if feat_output.shape[-1] != feat_dim:\n",
        "                print(f\"Adjusting output for discrete feature with dim {feat_dim}\")\n",
        "                feat_output = F.pad(feat_output, (0, feat_dim - feat_output.shape[-1]))\n",
        "            output_disc_list.append(feat_output)\n",
        "            start_idx = end_idx\n",
        "        output_disc = torch.cat(output_disc_list, dim=-1)\n",
        "\n",
        "        print(f\"Forward method output shapes - cont: {output_cont.shape}, disc: {output_disc.shape}\")\n",
        "        return output_cont, output_disc\n",
        "\n",
        "    def dynamic_thresholding(self, x, p):\n",
        "        # Reshape pour appliquer le seuillage sur chaque séquence indépendamment\n",
        "        batch_size, seq_len, feature_dim = x.shape\n",
        "        x_flat = x.reshape(batch_size * seq_len, feature_dim)\n",
        "\n",
        "        s = torch.quantile(torch.abs(x_flat), p, dim=1)\n",
        "        s = torch.clamp(s, min=1.0).unsqueeze(1)\n",
        "\n",
        "        x_thresholded = torch.clamp(x_flat, -s, s) / s\n",
        "\n",
        "        # Reshape pour revenir à la forme originale\n",
        "        return x_thresholded.reshape(batch_size, seq_len, feature_dim)\n",
        "\n",
        "\n",
        "    # ... (keep other methods the same)\n",
        "    def to(self, device):\n",
        "        super().to(device)\n",
        "        if hasattr(self, 'alphas_cumprod'):\n",
        "            self.alphas_cumprod = self.alphas_cumprod.to(device)\n",
        "        if hasattr(self, 'alphas'):\n",
        "            self.alphas = self.alphas.to(device)\n",
        "        if hasattr(self, 'betas'):\n",
        "            self.betas = self.betas.to(device)\n",
        "        return self\n",
        "\n",
        "    def compute_score(self, x, t, c=None):\n",
        "        x_cont, x_disc = x[:, :, :self.num_numeric_features], x[:, :, self.num_numeric_features:]\n",
        "\n",
        "        output_cont, output_disc = self(x, t, c)\n",
        "\n",
        "        lambda_t = self.interpolate_alphas_cumprod(t).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "        score_cont = (1 / torch.sqrt(lambda_t)) * (output_cont - x_cont / torch.sqrt(lambda_t))\n",
        "        score_disc = (1 / torch.sqrt(lambda_t)) * (output_disc - x_disc / torch.sqrt(lambda_t))\n",
        "\n",
        "        return torch.cat([score_cont, score_disc], dim=-1).float()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compute_loss(self, x_0, x_t, t):\n",
        "        print(f\"Compute loss input shapes - x_0: {x_0.shape}, x_t: {type(x_t)}, t: {t.shape}\")\n",
        "        predicted_noise_cont, predicted_noise_disc = self(x_t, t)\n",
        "        print(f\"Predicted noise shapes - cont: {predicted_noise_cont.shape}, disc: {predicted_noise_disc.shape}\")\n",
        "\n",
        "        # Unpack x_t if it's a tuple\n",
        "        if isinstance(x_t, tuple):\n",
        "            x_t_cont, x_t_disc = x_t\n",
        "        else:\n",
        "            x_t_cont = x_t[:, :, :self.num_numeric_features]\n",
        "            x_t_disc = x_t[:, :, self.num_numeric_features:]\n",
        "\n",
        "        total_loss = 0  # Utilisation d'une nouvelle variable pour accumuler la perte\n",
        "        start_idx = 0\n",
        "        for i, (feat_type, feat_dim) in enumerate(zip(self.feature_types, self.feature_dims)):\n",
        "            end_idx = start_idx + feat_dim\n",
        "            if feat_type == 'continuous':\n",
        "                pred = predicted_noise_cont[:, :, start_idx:end_idx]\n",
        "                target = x_0[:, :, start_idx:end_idx] - x_t_cont[:, :, start_idx:end_idx]\n",
        "                total_loss = total_loss + F.mse_loss(pred, target)  # Addition au lieu de +=\n",
        "            else:  # discrete\n",
        "                pred = predicted_noise_disc[:, :, start_idx:end_idx]\n",
        "                target = x_0[:, :, start_idx:end_idx].long()\n",
        "                print(f\"Before reshape - Discrete feature {i}:\")\n",
        "                print(f\"  pred shape: {pred.shape}, pred size: {pred.numel()}\")\n",
        "                print(f\"  target shape: {target.shape}, target size: {target.numel()}\")\n",
        "                print(f\"  feat_dim: {feat_dim}\")\n",
        "\n",
        "                # Reshape pred and target\n",
        "                batch_size, seq_len, pred_classes = pred.shape\n",
        "                pred_reshaped = pred.reshape(-1, pred_classes)\n",
        "                target_reshaped = target.reshape(-1)\n",
        "                print(f\"After reshape - Discrete feature {i}:\")\n",
        "                print(f\"  pred_reshaped shape: {pred_reshaped.shape}, pred_reshaped size: {pred_reshaped.numel()}\")\n",
        "                print(f\"  target_reshaped shape: {target_reshaped.shape}, target_reshaped size: {target_reshaped.numel()}\")\n",
        "\n",
        "                # Ensure pred and target have the same first dimension\n",
        "                min_size = min(pred_reshaped.shape[0], target_reshaped.shape[0])\n",
        "                pred_reshaped = pred_reshaped[:min_size]\n",
        "                target_reshaped = target_reshaped[:min_size]\n",
        "\n",
        "                # Handle mismatch in number of classes\n",
        "                if pred_classes != feat_dim:\n",
        "                    print(f\"Warning: Mismatch in number of classes for feature {i}. Pred: {pred_classes}, Expected: {feat_dim}\")\n",
        "                    # Option 1: Truncate or pad the predictions\n",
        "                    if pred_classes < feat_dim:\n",
        "                        pred_reshaped = F.pad(pred_reshaped, (0, feat_dim - pred_classes))\n",
        "                    else:\n",
        "                        pred_reshaped = pred_reshaped[:, :feat_dim]\n",
        "                    # Option 2: Adjust the target (use this if the model's prediction is correct)\n",
        "                    # target_reshaped = torch.clamp(target_reshaped, 0, pred_classes - 1)\n",
        "\n",
        "                print(f\"Final - Discrete feature {i}:\")\n",
        "                print(f\"  pred_reshaped shape: {pred_reshaped.shape}, pred_reshaped size: {pred_reshaped.numel()}\")\n",
        "                print(f\"  target_reshaped shape: {target_reshaped.shape}, target_reshaped size: {target_reshaped.numel()}\")\n",
        "\n",
        "                total_loss = total_loss + F.cross_entropy(pred_reshaped, target_reshaped)  # Addition au lieu de +=\n",
        "            start_idx = end_idx\n",
        "\n",
        "        print(f\"Computed loss: {total_loss.item()}\")\n",
        "        return total_loss\n",
        "\n",
        "    # ... (keep other methods the same)\n",
        "\n",
        "\n",
        "    def interpolate_alphas_cumprod(self, t):\n",
        "        return self._interpolate_tensor(self.alphas_cumprod, t)\n",
        "\n",
        "    def interpolate_alphas(self, t):\n",
        "        return self._interpolate_tensor(self.alphas, t)\n",
        "\n",
        "    def interpolate_betas(self, t):\n",
        "        return self._interpolate_tensor(self.betas, t)\n",
        "\n",
        "    def _interpolate_tensor(self, tensor, t):\n",
        "        low = torch.floor(t).long()\n",
        "        high = torch.ceil(t).long()\n",
        "        w = t - low.float()\n",
        "        return (1 - w) * tensor[low] + w * tensor[high]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_timestep_embedding(timesteps, embedding_dim):\n",
        "        assert len(timesteps.shape) == 1, \"Timesteps should be a 1-D tensor\"\n",
        "        half_dim = embedding_dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
        "        emb = emb.to(device=timesteps.device)\n",
        "        emb = timesteps.float()[:, None] * emb[None, :]\n",
        "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        if embedding_dim % 2 == 1:  # zero pad\n",
        "            emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
        "        return emb\n",
        "\n",
        "# Helper classes (AttentionLayer, ResidualBlock, SinusoidalPositionEmbeddings) remain the same as in the previous response"
      ],
      "metadata": {
        "id": "HJ9uWnMr49Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedDiffusionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim=128, time_dim=128, seq_length=10,\n",
        "                 num_layers=4, num_heads=8, num_numeric_features=0,\n",
        "                 alphas_cumprod=None, alphas=None, betas=None, num_classes=1000,\n",
        "                 feature_types=None, feature_dims=None, feature_specific_params=None,\n",
        "                 dynamic_thresholding_ratio=0.995, interval_min=-1, interval_max=1):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.time_dim = time_dim\n",
        "        self.seq_length = seq_length\n",
        "        self.num_numeric_features = num_numeric_features\n",
        "        self.num_classes = num_classes\n",
        "        self.feature_types = feature_types or ['continuous'] * input_dim\n",
        "        self.feature_dims = feature_dims or [1] * input_dim\n",
        "        assert len(self.feature_types) == len(self.feature_dims), \"feature_types and feature_dims must have the same length\"\n",
        "        assert sum(self.feature_dims) == input_dim, f\"Sum of feature_dims ({sum(self.feature_dims)}) must equal input_dim ({input_dim})\"\n",
        "\n",
        "        self.dynamic_thresholding_ratio = dynamic_thresholding_ratio\n",
        "        self.interval_min = interval_min\n",
        "        self.interval_max = interval_max\n",
        "        self.dynamic_thresholding_ratio = 0.995\n",
        "\n",
        "         # Paramètres par défaut\n",
        "        self.default_interval_min = interval_min\n",
        "        self.default_interval_max = interval_max\n",
        "        self.default_dynamic_thresholding_ratio = dynamic_thresholding_ratio\n",
        "\n",
        "        # Paramètres spécifiques aux caractéristiques\n",
        "        self.feature_specific_params = feature_specific_params or {}\n",
        "\n",
        "        # Register buffers\n",
        "        if alphas_cumprod is not None:\n",
        "            self.register_buffer('alphas_cumprod', torch.tensor(alphas_cumprod, dtype=torch.float32))\n",
        "        if alphas is not None:\n",
        "            self.register_buffer('alphas', torch.tensor(alphas, dtype=torch.float32))\n",
        "        if betas is not None:\n",
        "            self.register_buffer('betas', torch.tensor(betas, dtype=torch.float32))\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_dim),\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "            nn.Mish(),\n",
        "            nn.LayerNorm(time_dim),\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "        )\n",
        "\n",
        "        self.input_upscale = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Mish()\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(hidden_dim + time_dim, hidden_dim),\n",
        "                nn.LayerNorm(hidden_dim),\n",
        "                nn.Mish(),\n",
        "                ResidualBlock(hidden_dim)\n",
        "            ) for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.attention_layers = nn.ModuleList([\n",
        "            AttentionLayer(hidden_dim, num_heads=num_heads)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.class_embedding = nn.Embedding(num_classes + 1, hidden_dim)\n",
        "\n",
        "\n",
        "        print(f\"Model initialized with input_dim: {input_dim}, output_dim: {output_dim}\")\n",
        "        print(f\"Feature types: {feature_types}\")\n",
        "        print(f\"Feature dimensions: {feature_dims}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, t, c=None):\n",
        "        if isinstance(x, tuple):\n",
        "            x_cont, x_disc = x\n",
        "            print(f\"Forward input - cont shape: {x_cont.shape}, disc shape: {x_disc.shape}\")\n",
        "            x = torch.cat([x_cont, x_disc], dim=-1)\n",
        "\n",
        "        #print(f\"Forward method input shapes - x: {x.shape}, t: {t.shape}\")\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Time embedding\n",
        "        t_emb = self.time_mlp(t)\n",
        "        t_emb = t_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Process input\n",
        "        x = self.input_upscale(x)\n",
        "        x, _ = self.rnn(x)\n",
        "\n",
        "        # Apply layers with attention\n",
        "        for layer, attention in zip(self.layers, self.attention_layers):\n",
        "            x = layer(torch.cat([x, t_emb], dim=-1))\n",
        "            x = attention(x)\n",
        "\n",
        "        if c is None:\n",
        "            c = torch.full((x.shape[0],), self.num_classes, device=x.device)\n",
        "        else:\n",
        "            c = torch.where(c == -1, self.num_classes, c)\n",
        "\n",
        "        if c.dim() == 1:\n",
        "            c = c.unsqueeze(1).expand(-1, x.size(1))\n",
        "\n",
        "        class_emb = self.class_embedding(c)\n",
        "        x = x + class_emb\n",
        "\n",
        "        output = self.output_layer(x)\n",
        "        output_cont = output[:, :, :self.num_numeric_features]\n",
        "        output_disc = output[:, :, self.num_numeric_features:]\n",
        "\n",
        "        # Appliquer le limited interval et le dynamic thresholding spécifique à chaque caractéristique\n",
        "        for i in range(self.num_numeric_features):\n",
        "            feature = f\"numeric_{i}\"\n",
        "            params = self.feature_specific_params.get(feature, {})\n",
        "            interval_min = params.get('interval_min', self.default_interval_min)\n",
        "            interval_max = params.get('interval_max', self.default_interval_max)\n",
        "            dt_ratio = params.get('dynamic_thresholding_ratio', self.default_dynamic_thresholding_ratio)\n",
        "\n",
        "            # Utiliser des opérations qui créent de nouveaux tenseurs\n",
        "            output_cont_i = torch.clamp(output_cont[:, :, i:i+1], interval_min, interval_max)\n",
        "            output_cont_i = self.dynamic_thresholding(output_cont_i, dt_ratio)\n",
        "            output_cont = torch.cat([output_cont[:, :, :i], output_cont_i, output_cont[:, :, i+1:]], dim=2)\n",
        "\n",
        "\n",
        "        # Appliquer le limited interval aux sorties continues\n",
        "        output_cont = torch.clamp(output_cont, self.interval_min, self.interval_max)\n",
        "\n",
        "        # Appliquer le dynamic thresholding aux sorties continues\n",
        "        output_cont = self.dynamic_thresholding(output_cont, self.dynamic_thresholding_ratio)\n",
        "\n",
        "        # Traitement des sorties discrètes\n",
        "        output_disc_list = []\n",
        "        start_idx = 0\n",
        "        for feat_dim in self.feature_dims[self.num_numeric_features:]:\n",
        "            end_idx = start_idx + feat_dim\n",
        "            feat_output = output_disc[:, :, start_idx:end_idx]\n",
        "            if feat_output.shape[-1] != feat_dim:\n",
        "                print(f\"Adjusting output for discrete feature with dim {feat_dim}\")\n",
        "                feat_output = F.pad(feat_output, (0, feat_dim - feat_output.shape[-1]))\n",
        "            output_disc_list.append(feat_output)\n",
        "            start_idx = end_idx\n",
        "        output_disc = torch.cat(output_disc_list, dim=-1)\n",
        "\n",
        "        print(f\"Forward method output shapes - cont: {output_cont.shape}, disc: {output_disc.shape}\")\n",
        "        return output_cont, output_disc\n",
        "\n",
        "    def dynamic_thresholding(self, x, p):\n",
        "        # Reshape pour appliquer le seuillage sur chaque séquence indépendamment\n",
        "        batch_size, seq_len, feature_dim = x.shape\n",
        "        x_flat = x.reshape(batch_size * seq_len, feature_dim)\n",
        "\n",
        "        s = torch.quantile(torch.abs(x_flat), p, dim=1)\n",
        "        s = torch.clamp(s, min=1.0).unsqueeze(1)\n",
        "\n",
        "        x_thresholded = torch.clamp(x_flat, -s, s) / s\n",
        "\n",
        "        # Reshape pour revenir à la forme originale\n",
        "        return x_thresholded.reshape(batch_size, seq_len, feature_dim)\n",
        "\n",
        "\n",
        "    # ... (keep other methods the same)\n",
        "    def to(self, device):\n",
        "        super().to(device)\n",
        "        if hasattr(self, 'alphas_cumprod'):\n",
        "            self.alphas_cumprod = self.alphas_cumprod.to(device)\n",
        "        if hasattr(self, 'alphas'):\n",
        "            self.alphas = self.alphas.to(device)\n",
        "        if hasattr(self, 'betas'):\n",
        "            self.betas = self.betas.to(device)\n",
        "        return self\n",
        "\n",
        "    def compute_score(self, x, t, c=None):\n",
        "        x_cont, x_disc = x[:, :, :self.num_numeric_features], x[:, :, self.num_numeric_features:]\n",
        "\n",
        "        output_cont, output_disc = self(x, t, c)\n",
        "\n",
        "        lambda_t = self.interpolate_alphas_cumprod(t).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "        score_cont = (1 / torch.sqrt(lambda_t)) * (output_cont - x_cont / torch.sqrt(lambda_t))\n",
        "        score_disc = (1 / torch.sqrt(lambda_t)) * (output_disc - x_disc / torch.sqrt(lambda_t))\n",
        "\n",
        "        return torch.cat([score_cont, score_disc], dim=-1).float()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compute_loss(self, x_0, x_t, t):\n",
        "        print(f\"Compute loss input shapes - x_0: {x_0.shape}, x_t: {type(x_t)}, t: {t.shape}\")\n",
        "        predicted_noise_cont, predicted_noise_disc = self(x_t, t)\n",
        "        print(f\"Predicted noise shapes - cont: {predicted_noise_cont.shape}, disc: {predicted_noise_disc.shape}\")\n",
        "\n",
        "        # Unpack x_t if it's a tuple\n",
        "        if isinstance(x_t, tuple):\n",
        "            x_t_cont, x_t_disc = x_t\n",
        "        else:\n",
        "            x_t_cont = x_t[:, :, :self.num_numeric_features]\n",
        "            x_t_disc = x_t[:, :, self.num_numeric_features:]\n",
        "\n",
        "        total_loss = 0  # Utilisation d'une nouvelle variable pour accumuler la perte\n",
        "        start_idx = 0\n",
        "        for i, (feat_type, feat_dim) in enumerate(zip(self.feature_types, self.feature_dims)):\n",
        "        if feat_type == 'discrete':\n",
        "            pred = predicted_noise_disc[:, :, start_idx:end_idx]\n",
        "            target = x_0[:, :, start_idx:end_idx].long()\n",
        "\n",
        "            # Ajuster la dimension des prédictions si nécessaire\n",
        "            if pred.shape[-1] != feat_dim:\n",
        "                if pred.shape[-1] < feat_dim:\n",
        "                    pred = F.pad(pred, (0, feat_dim - pred.shape[-1]))\n",
        "                else:\n",
        "                    pred = pred[:, :, :feat_dim]\n",
        "\n",
        "            pred_reshaped = pred.reshape(-1, feat_dim)\n",
        "            target_reshaped = target.reshape(-1)\n",
        "\n",
        "            loss = loss + F.cross_entropy(pred_reshaped, target_reshaped)# Addition au lieu de +=\n",
        "            else:  # discrete\n",
        "                pred = predicted_noise_disc[:, :, start_idx:end_idx]\n",
        "                target = x_0[:, :, start_idx:end_idx].long()\n",
        "                print(f\"Before reshape - Discrete feature {i}:\")\n",
        "                print(f\"  pred shape: {pred.shape}, pred size: {pred.numel()}\")\n",
        "                print(f\"  target shape: {target.shape}, target size: {target.numel()}\")\n",
        "                print(f\"  feat_dim: {feat_dim}\")\n",
        "\n",
        "                # Reshape pred and target\n",
        "                batch_size, seq_len, pred_classes = pred.shape\n",
        "                pred_reshaped = pred.reshape(-1, pred_classes)\n",
        "                target_reshaped = target.reshape(-1)\n",
        "                print(f\"After reshape - Discrete feature {i}:\")\n",
        "                print(f\"  pred_reshaped shape: {pred_reshaped.shape}, pred_reshaped size: {pred_reshaped.numel()}\")\n",
        "                print(f\"  target_reshaped shape: {target_reshaped.shape}, target_reshaped size: {target_reshaped.numel()}\")\n",
        "\n",
        "                # Ensure pred and target have the same first dimension\n",
        "                min_size = min(pred_reshaped.shape[0], target_reshaped.shape[0])\n",
        "                pred_reshaped = pred_reshaped[:min_size]\n",
        "                target_reshaped = target_reshaped[:min_size]\n",
        "\n",
        "                # Handle mismatch in number of classes\n",
        "                if pred_classes != feat_dim:\n",
        "                    print(f\"Warning: Mismatch in number of classes for feature {i}. Pred: {pred_classes}, Expected: {feat_dim}\")\n",
        "                    # Option 1: Truncate or pad the predictions\n",
        "                    if pred_classes < feat_dim:\n",
        "                        pred_reshaped = F.pad(pred_reshaped, (0, feat_dim - pred_classes))\n",
        "                    else:\n",
        "                        pred_reshaped = pred_reshaped[:, :feat_dim]\n",
        "                    # Option 2: Adjust the target (use this if the model's prediction is correct)\n",
        "                    # target_reshaped = torch.clamp(target_reshaped, 0, pred_classes - 1)\n",
        "\n",
        "                print(f\"Final - Discrete feature {i}:\")\n",
        "                print(f\"  pred_reshaped shape: {pred_reshaped.shape}, pred_reshaped size: {pred_reshaped.numel()}\")\n",
        "                print(f\"  target_reshaped shape: {target_reshaped.shape}, target_reshaped size: {target_reshaped.numel()}\")\n",
        "\n",
        "                total_loss = total_loss + F.cross_entropy(pred_reshaped, target_reshaped)  # Addition au lieu de +=\n",
        "            start_idx = end_idx\n",
        "\n",
        "        print(f\"Computed loss: {total_loss.item()}\")\n",
        "        return total_loss\n",
        "\n",
        "    # ... (keep other methods the same)\n",
        "\n",
        "\n",
        "    def interpolate_alphas_cumprod(self, t):\n",
        "        return self._interpolate_tensor(self.alphas_cumprod, t)\n",
        "\n",
        "    def interpolate_alphas(self, t):\n",
        "        return self._interpolate_tensor(self.alphas, t)\n",
        "\n",
        "    def interpolate_betas(self, t):\n",
        "        return self._interpolate_tensor(self.betas, t)\n",
        "\n",
        "    def _interpolate_tensor(self, tensor, t):\n",
        "        low = torch.floor(t).long()\n",
        "        high = torch.ceil(t).long()\n",
        "        w = t - low.float()\n",
        "        return (1 - w) * tensor[low] + w * tensor[high]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_timestep_embedding(timesteps, embedding_dim):\n",
        "        assert len(timesteps.shape) == 1, \"Timesteps should be a 1-D tensor\"\n",
        "        half_dim = embedding_dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
        "        emb = emb.to(device=timesteps.device)\n",
        "        emb = timesteps.float()[:, None] * emb[None, :]\n",
        "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        if embedding_dim % 2 == 1:  # zero pad\n",
        "            emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
        "        return emb\n",
        "\n",
        "# Helper classes (AttentionLayer, ResidualBlock, SinusoidalPositionEmbeddings) remain the same as in the previous response"
      ],
      "metadata": {
        "id": "DQb8RP8q4-p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import wasserstein_distance\n",
        "from scipy.spatial.distance import jensenshannon\n",
        "import math\n",
        "import scipy\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8):\n",
        "        super().__init__()\n",
        "        self.attention = nn.MultiheadAttention(dim, num_heads=num_heads, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(dim, 4 * dim),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(4 * dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        x = self.norm1(x + attn_output)\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + ff_output)\n",
        "        return x\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class DiffusionModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim=256, time_dim=256, seq_length=30, num_numeric_features=0, alphas_cumprod=None, alphas=None, betas=None, num_classes=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.time_dim = time_dim\n",
        "        self.seq_length = seq_length\n",
        "        self.num_numeric_features = num_numeric_features\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Only register buffers if they are not None\n",
        "        if alphas_cumprod is not None:\n",
        "            self.register_buffer('alphas_cumprod', torch.tensor(alphas_cumprod, dtype=torch.float32))\n",
        "        if alphas is not None:\n",
        "            self.register_buffer('alphas', torch.tensor(alphas, dtype=torch.float32))\n",
        "        if betas is not None:\n",
        "            self.register_buffer('betas', torch.tensor(betas, dtype=torch.float32))\n",
        "\n",
        "        # Rest of the initialization code...\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            SinusoidalPositionEmbeddings(time_dim),\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_dim, time_dim),\n",
        "        )\n",
        "\n",
        "        self.input_upscale = nn.Linear(input_dim, hidden_dim)\n",
        "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
        "        self.attention = AttentionLayer(hidden_dim)\n",
        "\n",
        "        self.output_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dim + time_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            ResidualBlock(hidden_dim),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            ResidualBlock(hidden_dim),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "        self.class_embedding = nn.Embedding(num_classes + 1, hidden_dim)\n",
        "\n",
        "\n",
        "    def to(self, device):\n",
        "        super().to(device)\n",
        "        self.alphas_cumprod = self.alphas_cumprod.to(device)\n",
        "        self.alphas = self.alphas.to(device)\n",
        "        self.betas = self.betas.to(device)\n",
        "        return self\n",
        "\n",
        "    def forward(self, x, t, c= None):\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Time embedding\n",
        "        t_emb = self.time_mlp(t)\n",
        "\n",
        "        t_emb = t_emb.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "        # Process input\n",
        "        x = self.input_upscale(x)\n",
        "        x, _ = self.rnn(x)\n",
        "        x = self.attention(x)\n",
        "\n",
        "\n",
        "        if c is None:\n",
        "            # For unconditional generation, use the last embedding (num_classes)\n",
        "            c = torch.full((x.shape[0],), self.num_classes, device=x.device)\n",
        "        else:\n",
        "            c = torch.where(c == -1, self.num_classes, c)\n",
        "\n",
        "        if c.dim() == 1:\n",
        "            c = c.unsqueeze(1).expand(-1, x.size(1))\n",
        "\n",
        "        class_emb = self.class_embedding(c)\n",
        "\n",
        "        x = x + class_emb\n",
        "\n",
        "\n",
        "        # Combine with time embedding\n",
        "        x = torch.cat([x, t_emb], dim=-1)\n",
        "\n",
        "        output = self.output_layer(x)\n",
        "        output_cont = output[:, :, :self.num_numeric_features]\n",
        "        output_disc = output[:, :, self.num_numeric_features:]\n",
        "\n",
        "        # Apply Gumbel-Softmax to discrete output\n",
        "        output_disc = F.gumbel_softmax(output_disc, tau=1.0, hard=False, dim=-1)\n",
        "\n",
        "        return output_cont, output_disc\n",
        "\n",
        "    def compute_score(self, x, t, c=None):\n",
        "        x_cont, x_disc = x[:, :, :self.num_numeric_features], x[:, :, self.num_numeric_features:]\n",
        "\n",
        "        output_cont, output_disc = self.model(x, t, c)  # c can be None here\n",
        "\n",
        "        lambda_t = self.interpolate_alphas_cumprod(t).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "        score_cont = (1 / torch.sqrt(lambda_t)) * (output_cont - x_cont / torch.sqrt(lambda_t))\n",
        "        score_disc = (1 / torch.sqrt(lambda_t)) * (output_disc - x_disc / torch.sqrt(lambda_t))\n",
        "\n",
        "        return torch.cat([score_cont, score_disc], dim=-1).float()\n",
        "\n",
        "    def compute_loss(self, x_0, x_t, t):\n",
        "        predicted_noise = self(x_t, t)\n",
        "\n",
        "        loss = 0\n",
        "        for i, feat_type in enumerate(self.feature_types):\n",
        "            if feat_type == 'continuous':\n",
        "                loss += F.mse_loss(predicted_noise[:, :, i], x_0[:, :, i] - x_t[:, :, i])\n",
        "            else:  # discrete\n",
        "                loss += F.cross_entropy(predicted_noise[:, :, i].view(-1, predicted_noise.shape[-1]), x_0[:, :, i].long().view(-1))\n",
        "\n",
        "        return loss\n",
        "    def interpolate_alphas_cumprod(self, t):\n",
        "        # Interpolate alphas_cumprod for float timesteps\n",
        "        low = torch.floor(t).long()\n",
        "        high = torch.ceil(t).long()\n",
        "        w = t - low.float()\n",
        "        return (1 - w) * self.alphas_cumprod[low] + w * self.alphas_cumprod[high]\n",
        "    def interpolate_alphas(self, t):\n",
        "        return self._interpolate_tensor(self.alphas, t)\n",
        "\n",
        "    def interpolate_betas(self, t):\n",
        "        return self._interpolate_tensor(self.betas, t)\n",
        "\n",
        "    def _interpolate_tensor(self, tensor, t):\n",
        "        low = torch.floor(t).long()\n",
        "        high = torch.ceil(t).long()\n",
        "        w = t - low.float()\n",
        "        return (1 - w) * tensor[low] + w * tensor[high]\n",
        "\n",
        "    @staticmethod\n",
        "    def get_timestep_embedding(timesteps, embedding_dim):\n",
        "        assert len(timesteps.shape) == 1, \"Timesteps should be a 1-D tensor\"\n",
        "        half_dim = embedding_dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n",
        "        emb = emb.to(device=timesteps.device)\n",
        "        emb = timesteps.float()[:, None] * emb[None, :]\n",
        "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        if embedding_dim % 2 == 1:  # zero pad\n",
        "            emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n",
        "        return emb\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
        "        def sample_gumbel(shape, eps=1e-10, device=None):\n",
        "            U = torch.rand(shape, device=device)\n",
        "            return -torch.log(-torch.log(U + eps) + eps)\n",
        "\n",
        "        device = logits.device\n",
        "        gumbels = sample_gumbel(logits.shape, eps=eps, device=device)\n",
        "        gumbels = (logits + gumbels) / tau\n",
        "        y_soft = gumbels.softmax(dim)\n",
        "\n",
        "        if hard:\n",
        "            index = y_soft.max(dim, keepdim=True)[1]\n",
        "            y_hard = torch.zeros_like(logits, device=device).scatter_(dim, index, 1.0)\n",
        "            ret = y_hard - y_soft.detach() + y_soft\n",
        "        else:\n",
        "            ret = y_soft\n",
        "        return ret\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class FinDiffusionPlus:\n",
        "\n",
        "    def __init__(self, n_timesteps=200, n_noise=200, learning_rate=0.001, seq_length=30, epsilon=1e-8, p_uncond=0.1):\n",
        "        self.n_timesteps = n_timesteps\n",
        "        self.n_noise = n_noise\n",
        "        self.learning_rate = learning_rate\n",
        "        self.seq_length = seq_length\n",
        "        self.epsilon = epsilon\n",
        "        self.p_uncond = p_uncond\n",
        "        self.feature_types = None\n",
        "        self.target_column = 'target'\n",
        "\n",
        "        # Set up device\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        # Use cosine beta schedule\n",
        "        self.betas = self.cosine_beta_schedule(n_timesteps).to(self.device)\n",
        "        self.alphas = (1. - self.betas).to(self.device)\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0).to(self.device)\n",
        "\n",
        "\n",
        "        # Move to GPU if available\n",
        "        try:\n",
        "            self.betas = self.betas.to(self.device)\n",
        "            self.alphas = self.alphas.to(self.device)\n",
        "            self.alphas_cumprod = self.alphas_cumprod.to(self.device)\n",
        "            print(\"Successfully moved tensors to GPU\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error moving tensors to GPU: {e}\")\n",
        "            print(\"Falling back to CPU\")\n",
        "            self.device = torch.device('cpu')\n",
        "\n",
        "        # Define noise schedule\n",
        "        self.noise_schedule = torch.linspace(1, 0.01, n_timesteps).to(self.device)\n",
        "\n",
        "        print(f\"alphas_cumprod shape: {self.alphas_cumprod.shape}\")\n",
        "\n",
        "        self.model = None\n",
        "        self.numeric_features = None\n",
        "        self.categorical_features = None\n",
        "        self.input_dim = None\n",
        "\n",
        "    def cosine_beta_schedule(self,timesteps, s=0.008):\n",
        "        steps = timesteps + 1\n",
        "        x = torch.linspace(0, timesteps, steps)\n",
        "        alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
        "        alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "        betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "        return torch.clip(betas, 0.0001, 0.9999)\n",
        "    def preprocess_data(self, data_path):\n",
        "        df = pd.read_csv(data_path)\n",
        "        X = df.drop([self.target_column], axis=1)\n",
        "        y = df[self.target_column]\n",
        "\n",
        "        self.numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "        self.categorical_features = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "        # Preprocess numeric features\n",
        "        self.numeric_scaler = StandardScaler()\n",
        "        X[self.numeric_features] = self.numeric_scaler.fit_transform(X[self.numeric_features])\n",
        "\n",
        "        # Preprocess categorical features\n",
        "        self.categorical_encoders = {}\n",
        "        for cat_feature in self.categorical_features:\n",
        "            encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "            encoded = encoder.fit_transform(X[[cat_feature]])\n",
        "            encoded_df = pd.DataFrame(encoded, columns=[f\"{cat_feature}_{cat}\" for cat in encoder.categories_[0]])\n",
        "            X = pd.concat([X.drop(columns=[cat_feature]), encoded_df], axis=1)\n",
        "            self.categorical_encoders[cat_feature] = encoder\n",
        "\n",
        "\n",
        "        self.feature_types = ['continuous'] * len(self.numeric_features)\n",
        "        self.feature_dims = [1] * len(self.numeric_features)\n",
        "        for encoder in self.categorical_encoders.values():\n",
        "            self.feature_types.append('discrete')\n",
        "            self.feature_dims.append(len(encoder.categories_[0]))\n",
        "\n",
        "        # Set input dimension\n",
        "        self.input_dim = sum(self.feature_dims)\n",
        "\n",
        "\n",
        "\n",
        "        # Create sequences\n",
        "        X_seq = self.create_sequences(X.values, self.seq_length)\n",
        "        y_encoded = pd.factorize(y)[0]\n",
        "\n",
        "        #self.input_dim = X.shape[1]\n",
        "        self.num_numeric_features = len(self.numeric_features)\n",
        "\n",
        "        if X_seq.shape[1] < self.seq_length:\n",
        "            pad_width = ((0, 0), (0, self.seq_length - X_seq.shape[1]), (0, 0))\n",
        "            X_seq = np.pad(X_seq, pad_width, mode='constant')\n",
        "        elif X_seq.shape[1] > self.seq_length:\n",
        "            X_seq = X_seq[:, :self.seq_length, :]\n",
        "\n",
        "        print(f\"Preprocessed data shape: {X_seq.shape}\")\n",
        "        print(f\"Number of numeric features: {len(self.numeric_features)}\")\n",
        "        print(f\"Number of categorical features: {len(self.categorical_features)}\")\n",
        "        print(f\"Feature types: {self.feature_types}\")\n",
        "        print(f\"Feature dimensions: {self.feature_dims}\")\n",
        "\n",
        "        return X_seq.astype(np.float32), y_encoded\n",
        "\n",
        "\n",
        "    def compute_score(self, x, t, c=None):\n",
        "        cond_score_cont, cond_score_disc = self.model(x, t, c)\n",
        "\n",
        "        if c is None:\n",
        "            # Si c est None, cela signifie que nous calculons le score inconditionnel\n",
        "            uncond_score_cont, uncond_score_disc = cond_score_cont, cond_score_disc\n",
        "        else:\n",
        "            # Créer un tenseur de -1 avec la même forme que c pour la génération inconditionnelle\n",
        "            uncond_c = torch.full_like(c, -1)\n",
        "            uncond_score_cont, uncond_score_disc = self.model(x, t, uncond_c)\n",
        "\n",
        "        return (cond_score_cont, cond_score_disc), (uncond_score_cont, uncond_score_disc)\n",
        "\n",
        "    def create_sequences(self, data, seq_length):\n",
        "        n_samples, n_features = data.shape\n",
        "        if n_samples < seq_length:\n",
        "            # If we have fewer samples than the sequence length, pad with zeros\n",
        "            pad_size = seq_length - n_samples\n",
        "            padded_data = np.pad(data, ((0, pad_size), (0, 0)), mode='constant')\n",
        "            return padded_data.reshape(1, seq_length, n_features)\n",
        "        else:\n",
        "            n_seq = n_samples - seq_length + 1\n",
        "            sequences = np.zeros((n_seq, seq_length, n_features))\n",
        "            for i in range(n_seq):\n",
        "                sequences[i] = data[i:i+seq_length]\n",
        "            return sequences\n",
        "\n",
        "\n",
        "    def forward_process(self, X, t):\n",
        "        X_cont = X[:, :, :self.num_numeric_features]\n",
        "        X_disc = X[:, :, self.num_numeric_features:]\n",
        "\n",
        "        noise_cont = torch.randn_like(X_cont, device=self.device)\n",
        "        noise_disc = torch.randn_like(X_disc, device=self.device)\n",
        "\n",
        "        alpha_cumprod = self.alphas_cumprod[t].unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "        X_cont_noisy = torch.sqrt(alpha_cumprod) * X_cont + torch.sqrt(1 - alpha_cumprod) * noise_cont\n",
        "\n",
        "        X_disc_noisy_list = []\n",
        "        for i, feat_dim in enumerate(self.feature_dims[self.num_numeric_features:]):\n",
        "            X_disc_feat = X_disc[:, :, i:i+feat_dim]\n",
        "            noise_disc_feat = noise_disc[:, :, i:i+feat_dim]\n",
        "            X_disc_noisy_feat = self.gumbel_softmax(X_disc_feat + noise_disc_feat, tau=1, hard=False)\n",
        "            X_disc_noisy_list.append(X_disc_noisy_feat)\n",
        "\n",
        "        X_disc_noisy = torch.cat(X_disc_noisy_list, dim=-1)\n",
        "\n",
        "        return X_cont_noisy, X_disc_noisy\n",
        "\n",
        "    def interpolate_alphas_cumprod(self, t):\n",
        "        # Interpolate alphas_cumprod for float timesteps\n",
        "        low = torch.floor(t).long()\n",
        "        high = torch.ceil(t).long()\n",
        "        w = t - low.float()\n",
        "        return (1 - w) * self.alphas_cumprod[low] + w * self.alphas_cumprod[high]\n",
        "\n",
        "    def reverse_process(self, X, t_tensor, score):\n",
        "        with torch.no_grad():\n",
        "            noise_level = self.noise_schedule[t_tensor].unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "            alpha = self.model.interpolate_alphas(t_tensor).unsqueeze(1).unsqueeze(1)\n",
        "            alpha_cumprod = self.model.interpolate_alphas_cumprod(t_tensor).unsqueeze(1).unsqueeze(1)\n",
        "            beta = self.model.interpolate_betas(t_tensor).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "            # Compute adaptive step size\n",
        "            step_size = 1.0 / (torch.norm(score, dim=-1, keepdim=True).clamp(min=self.epsilon))\n",
        "\n",
        "            # Annealed Langevin Dynamics update\n",
        "            noise = torch.randn_like(X)\n",
        "            X_new = X + step_size * ((1 - alpha) / torch.sqrt(1 - alpha_cumprod)) * score + \\\n",
        "                torch.sqrt(2 * step_size * noise_level) * noise\n",
        "\n",
        "        return X_new\n",
        "\n",
        "    def improved_loss_function(self, X, X_noisy, predicted_noise, t):\n",
        "        # Split into continuous and discrete parts\n",
        "        X_cont, X_disc = X[:, :, :self.num_numeric_features], X[:, :, self.num_numeric_features:]\n",
        "        X_noisy_cont, X_noisy_disc = X_noisy[:, :, :self.num_numeric_features], X_noisy[:, :, self.num_numeric_features:]\n",
        "        pred_noise_cont, pred_noise_disc = predicted_noise[:, :, :self.num_numeric_features], predicted_noise[:, :, self.num_numeric_features:]\n",
        "\n",
        "        # Continuous loss\n",
        "        cont_loss = F.mse_loss(pred_noise_cont, X_cont - X_noisy_cont)\n",
        "\n",
        "        # Discrete loss using KL divergence\n",
        "        disc_loss = F.kl_div(\n",
        "            F.log_softmax(pred_noise_disc, dim=-1),\n",
        "            F.softmax(X_disc, dim=-1),\n",
        "            reduction='batchmean'\n",
        "        )\n",
        "\n",
        "        # Combine losses with adaptive weighting\n",
        "        alpha = self.alphas_cumprod[t]\n",
        "        loss = alpha * cont_loss + (1 - alpha) * disc_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    \"\"\"def train(self, X, y):\n",
        "        print(f\"X shape: {X.shape}\")\n",
        "        print(f\"y shape: {y.shape}\")\n",
        "        X_tensor = torch.from_numpy(X).float().to(self.device).requires_grad_(True)\n",
        "        print(f\"X_tensor shape: {X_tensor.shape}\")\n",
        "        y_tensor = torch.from_numpy(y).long().to(self.device)\"\"\"\"\"\"\n",
        "\n",
        "        if self.model is None:\n",
        "            num_classes = len(np.unique(y))\n",
        "            self.model = DiffusionModel(\n",
        "                input_dim=X.shape[2],\n",
        "                output_dim=X.shape[2],\n",
        "                hidden_dim=512,\n",
        "                time_dim=512,\n",
        "                seq_length=self.seq_length,\n",
        "                num_numeric_features=len(self.numeric_features),\n",
        "                alphas_cumprod=self.alphas_cumprod.cpu().numpy(),\n",
        "                alphas=self.alphas.cpu().numpy(),\n",
        "                betas=self.betas.cpu().numpy(),\n",
        "                num_classes=num_classes).to(self.device)\"\"\"\"\"\"\n",
        "        self.model = EnhancedDiffusionModel(\n",
        "            input_dim=self.input_dim,\n",
        "            output_dim=self.input_dim,\n",
        "            hidden_dim=256,\n",
        "            time_dim=256,\n",
        "            seq_length=self.seq_length,\n",
        "            num_layers=4,\n",
        "            num_heads=8,\n",
        "            num_numeric_features=len(self.numeric_features),\n",
        "            alphas_cumprod=self.alphas_cumprod.cpu().numpy(),\n",
        "            alphas=self.alphas.cpu().numpy(),\n",
        "            betas=self.betas.cpu().numpy(),\n",
        "            num_classes=len(np.unique(y))\n",
        "        ).to(self.device)\n",
        "\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.n_timesteps)\n",
        "        try:\n",
        "\n",
        "\n",
        "            for epoch in range(self.n_timesteps):\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Sample a batch\n",
        "                batch_size = min(128, X.shape[0])  # Adjust batch size as needed\n",
        "                batch_indices = torch.randint(0, X.shape[0], (batch_size,))\n",
        "                X_batch = X_tensor[batch_indices]\n",
        "                y_batch = y_tensor[batch_indices]\n",
        "\n",
        "                t = torch.randint(0, self.n_timesteps, (batch_size,), device=self.device)\n",
        "\n",
        "                # Randomly decide whether to use conditional or unconditional training\n",
        "                use_uncond = torch.rand(batch_size, device=self.device) < self.p_uncond\n",
        "                c = torch.where(use_uncond, torch.full_like(y_batch, -1), y_batch)  # -1 represents unconditional\n",
        "\n",
        "                # Add noise\n",
        "                noise = torch.randn_like(X_batch)\n",
        "                X_noisy = self.add_noise(X_batch, t)\n",
        "\n",
        "                # Forward process\n",
        "                X_dilated = self.forward_process(X_noisy, t)\n",
        "\n",
        "                # Split into continuous and discrete parts\n",
        "                X_cont = X_batch[:, :, :self.num_numeric_features]\n",
        "                X_disc = X_batch[:, :, self.num_numeric_features:]\n",
        "                X_dilated_cont = X_dilated[:, :, :self.num_numeric_features]\n",
        "                X_dilated_disc = X_dilated[:, :, self.num_numeric_features:]\n",
        "\n",
        "                # Compute scores\n",
        "                score_cont, score_disc = self.model(X_dilated, t, c)\n",
        "                print(f\"score_cont shape: {score_cont.shape}, score_disc shape: {score_disc.shape}\")\n",
        "                # Compute losses\n",
        "                loss_cont = self.score_matching_loss_continuous(\n",
        "                    X_cont, X_dilated_cont, score_cont, t\n",
        "                )\n",
        "                loss_disc = self.score_matching_loss_discrete(\n",
        "                    X_disc, X_dilated_disc, score_disc, t\n",
        "                )\n",
        "\n",
        "                loss = loss_cont + loss_disc\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "\n",
        "                if (epoch + 1) % 100 == 0:\n",
        "                    print(f\"Epoch {epoch+1}/{self.n_timesteps}, Loss: {loss.item():.4f}, Loss Cont: {loss_cont.item():.4f}, Loss Disc: {loss_disc.item():.4f}\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error occurred: {e}\")\n",
        "            print(f\"Error type: {type(e).__name__}\")\n",
        "            print(f\"Error args: {e.args}\")\n",
        "            raise\n",
        "\n",
        "        return self.model\"\"\"\n",
        "\n",
        "    def train(self, X, y):\n",
        "        print(f\"X shape: {X.shape}\")\n",
        "        print(f\"y shape: {y.shape}\")\n",
        "        X_tensor = torch.from_numpy(X).float().to(self.device).requires_grad_(True)\n",
        "        print(f\"X_tensor shape: {X_tensor.shape}\")\n",
        "        y_tensor = torch.from_numpy(y).long().to(self.device)\n",
        "        feature_specific_params = {\n",
        "            'numeric_0': {'interval_min': 0, 'interval_max': 1, 'dynamic_thresholding_ratio': 0.99},  # liveness\n",
        "            'numeric_1': {'interval_min': 0, 'interval_max': 1, 'dynamic_thresholding_ratio': 0.99},  # speechiness\n",
        "            'numeric_2': {'interval_min': 0, 'interval_max': 1, 'dynamic_thresholding_ratio': 0.98},  # instrumentalness\n",
        "            'numeric_3': {'dynamic_thresholding_ratio': 0.97}  # mode\n",
        "        } # mode\n",
        "\n",
        "        if self.model is None:\n",
        "            num_classes = len(np.unique(y))\n",
        "            self.model = EnhancedDiffusionModel(\n",
        "                input_dim=X.shape[2],\n",
        "                output_dim=X.shape[2],\n",
        "                hidden_dim=128,\n",
        "                time_dim=128,\n",
        "                seq_length=self.seq_length,\n",
        "                num_layers=4,\n",
        "                num_heads=8,\n",
        "                num_numeric_features=len(self.numeric_features),\n",
        "                alphas_cumprod=self.alphas_cumprod.cpu().numpy(),\n",
        "                alphas=self.alphas.cpu().numpy(),\n",
        "                betas=self.betas.cpu().numpy(),\n",
        "                num_classes=num_classes,\n",
        "                feature_types=self.feature_types,\n",
        "                feature_dims=self.feature_dims,\n",
        "                feature_specific_params=feature_specific_params,\n",
        "                dynamic_thresholding_ratio=0.995,  # valeur par défaut\n",
        "                interval_min=-1,  # valeur par défaut\n",
        "                interval_max=1  # valeur par défaut\n",
        "            ).to(self.device)\n",
        "        self.optimizer = optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.n_timesteps)\n",
        "\n",
        "        try:\n",
        "            for epoch in range(self.n_timesteps):\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Sample a batch\n",
        "                batch_size = min(128, X.shape[0])\n",
        "                batch_indices = torch.randint(0, X.shape[0], (batch_size,))\n",
        "                X_batch = X_tensor[batch_indices].clone()  # Utiliser .clone() pour créer une copie\n",
        "                y_batch = y_tensor[batch_indices].clone()\n",
        "\n",
        "                t = torch.randint(0, self.n_timesteps, (batch_size,), device=self.device)\n",
        "\n",
        "                # Randomly decide whether to use conditional or unconditional training\n",
        "                use_uncond = torch.rand(batch_size, device=self.device) < self.p_uncond\n",
        "                c = torch.where(use_uncond, torch.full_like(y_batch, -1), y_batch)  # -1 represents unconditional\n",
        "\n",
        "                # Add noise\n",
        "                X_noisy = self.add_noise(X_batch, t)\n",
        "\n",
        "                # Forward process\n",
        "                X_dilated = self.forward_process(X_noisy, t)\n",
        "\n",
        "                # Compute scores\n",
        "                (cond_score_cont, cond_score_disc), (uncond_score_cont, uncond_score_disc) = self.compute_score(X_dilated, t, c)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = self.model.compute_loss(X_batch, X_dilated, t)\n",
        "\n",
        "                loss.backward()\n",
        "                # Vérification des gradients\n",
        "                for name, param in self.model.named_parameters():\n",
        "                    if param.grad is not None:\n",
        "                        if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n",
        "                            print(f\"Warning: NaN or Inf detected in gradients of {name}\")\n",
        "\n",
        "                # Gradient clipping\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "                self.optimizer.step()\n",
        "                self.scheduler.step()\n",
        "\n",
        "                if (epoch + 1) % 100 == 0:\n",
        "                    print(f\"Epoch {epoch+1}/{self.n_timesteps}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error occurred: {e}\")\n",
        "            print(f\"Error type: {type(e).__name__}\")\n",
        "            print(f\"Error args: {e.args}\")\n",
        "            raise\n",
        "\n",
        "        return self.model\n",
        "    def initialize_noise_schedule(self):\n",
        "        self.noise_schedule = torch.linspace(1, 0.01, self.n_timesteps).to(self.device)\n",
        "\n",
        "    def score_matching_loss_continuous(self, X_cont, X_cont_dilated, score_pred_cont, t):\n",
        "\n",
        "        lambda_t = self.model.interpolate_alphas_cumprod(t).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "        # Reshape tensors to combine batch and sequence dimensions\n",
        "        batch_size, seq_len, num_features = X_cont.shape\n",
        "        X_cont_flat = X_cont.reshape(-1, num_features)\n",
        "        X_cont_dilated_flat = X_cont_dilated.reshape(-1, num_features)\n",
        "        score_pred_cont_flat = score_pred_cont.reshape(-1, num_features)\n",
        "\n",
        "        # Expand lambda_t to match the flattened shape\n",
        "        lambda_t_expanded = lambda_t.expand(batch_size, seq_len, 1).reshape(-1, 1)\n",
        "\n",
        "        # Compute the true score\n",
        "        true_score = (X_cont_flat - torch.sqrt(lambda_t_expanded) * X_cont_dilated_flat) / (1 - lambda_t_expanded)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = F.mse_loss(score_pred_cont_flat, true_score)\n",
        "        print(f\"X_cont shape: {X_cont.shape}, X_cont_dilated shape: {X_cont_dilated.shape}\")\n",
        "        print(f\"score_pred_cont shape: {score_pred_cont.shape}, t shape: {t.shape}\")\n",
        "        return loss\n",
        "\n",
        "    def score_matching_loss_discrete(self, X_disc, X_disc_dilated, score_pred_disc, t):\n",
        "        lambda_t = self.model.interpolate_alphas_cumprod(t).unsqueeze(1).unsqueeze(1)\n",
        "\n",
        "        # Reshape tensors to combine batch and sequence dimensions\n",
        "        batch_size, seq_len, num_features = X_disc.shape\n",
        "        X_disc_flat = X_disc.reshape(-1, num_features)\n",
        "        X_disc_dilated_flat = X_disc_dilated.reshape(-1, num_features)\n",
        "        score_pred_disc_flat = score_pred_disc.reshape(-1, num_features)\n",
        "\n",
        "        # Expand lambda_t to match the flattened shape\n",
        "        lambda_t_expanded = lambda_t.expand(batch_size, seq_len, 1).reshape(-1, 1)\n",
        "\n",
        "        # Compute the true score\n",
        "        true_score = (X_disc_flat - X_disc_dilated_flat) / (1 - lambda_t_expanded)\n",
        "\n",
        "        # Compute the loss using binary cross-entropy for each feature independently\n",
        "        loss = F.binary_cross_entropy_with_logits(score_pred_disc_flat, true_score, reduction='none')\n",
        "\n",
        "        # Sum over features and average over batch and sequence\n",
        "        loss = loss.sum(dim=-1).mean()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def generate(self, n_samples, class_labels=None, guidance_strength=1):\n",
        "        X = torch.randn(n_samples, self.seq_length, self.input_dim, device=self.device)\n",
        "\n",
        "        if class_labels is None:\n",
        "            class_labels = torch.randint(0, self.model.num_classes, (n_samples,), device=self.device)\n",
        "        else:\n",
        "            class_labels = torch.tensor(class_labels, device=self.device)\n",
        "\n",
        "        for t in reversed(range(self.n_timesteps)):\n",
        "            t_tensor = torch.full((n_samples,), t, device=self.device)\n",
        "\n",
        "            (cond_score_cont, cond_score_disc), (uncond_score_cont, uncond_score_disc) = self.compute_score(X, t_tensor, class_labels)\n",
        "\n",
        "            # Apply classifier-free guidance\n",
        "            guided_score_cont = uncond_score_cont + guidance_strength * (cond_score_cont - uncond_score_cont)\n",
        "            guided_score_disc = uncond_score_disc + guidance_strength * (cond_score_disc - uncond_score_disc)\n",
        "\n",
        "            # Combine continuous and discrete scores\n",
        "            guided_score = torch.cat([guided_score_cont, guided_score_disc], dim=-1)\n",
        "\n",
        "            X = self.reverse_process(X, t_tensor, guided_score)\n",
        "\n",
        "        X_np = X[:, -1, :].detach().cpu().numpy()\n",
        "\n",
        "        # Split back into continuous and discrete parts\n",
        "        X_cont_np = X_np[:, :self.num_numeric_features]\n",
        "        X_disc_np = X_np[:, self.num_numeric_features:]\n",
        "\n",
        "        # Inverse transform numerical features\n",
        "        X_cont_inv = self.numeric_scaler.inverse_transform(X_cont_np)\n",
        "\n",
        "        X_disc_inv = []\n",
        "        start_idx = 0\n",
        "        for cat_feature, encoder in self.categorical_encoders.items():\n",
        "            end_idx = start_idx + len(encoder.categories_[0])\n",
        "\n",
        "            # Créer un vecteur one-hot à partir des indices\n",
        "            X_disc_cat = np.zeros((n_samples, len(encoder.categories_[0])))\n",
        "            cat_indices = np.argmax(X_disc_np[:, start_idx:end_idx], axis=1)\n",
        "            X_disc_cat[np.arange(n_samples), cat_indices] = 1\n",
        "\n",
        "            # Inverse transform\n",
        "            X_disc_inv.append(encoder.inverse_transform(X_disc_cat))\n",
        "            start_idx = end_idx\n",
        "\n",
        "        # Combine continuous and discrete data\n",
        "        X_generated = np.column_stack([X_cont_inv] + X_disc_inv)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        columns = list(self.numeric_features) + list(self.categorical_features)\n",
        "        X_generated_df = pd.DataFrame(X_generated, columns=columns)\n",
        "\n",
        "        return X_generated_df\n",
        "    \"\"\"\n",
        "    def generate(self, n_samples, class_labels=None, guidance_strength=0.0):\n",
        "        X = torch.randn(n_samples, self.seq_length, self.input_dim, device=self.device)\n",
        "\n",
        "        if class_labels is None:\n",
        "            class_labels = torch.randint(0, self.model.num_classes, (n_samples,), device=self.device)\n",
        "        else:\n",
        "            class_labels = torch.tensor(class_labels, device=self.device)\n",
        "\n",
        "        for t in reversed(range(self.n_timesteps)):\n",
        "            t_tensor = torch.full((n_samples,), t, device=self.device)\n",
        "\n",
        "            (cond_score_cont, cond_score_disc), (uncond_score_cont, uncond_score_disc) = self.compute_score(X, t_tensor, class_labels)\n",
        "\n",
        "            # Apply classifier-free guidance\n",
        "            guided_score_cont = uncond_score_cont + guidance_strength * (cond_score_cont - uncond_score_cont)\n",
        "            guided_score_disc = uncond_score_disc + guidance_strength * (cond_score_disc - uncond_score_disc)\n",
        "\n",
        "            # Combine continuous and discrete scores\n",
        "            guided_score = torch.cat([guided_score_cont, guided_score_disc], dim=-1)\n",
        "\n",
        "            X = self.reverse_process(X, t_tensor, guided_score)\n",
        "\n",
        "        X_np = X[:, -1, :].detach().cpu().numpy()\n",
        "\n",
        "        # Split back into continuous and discrete parts\n",
        "        X_cont_np = X_np[:, :self.num_numeric_features]\n",
        "        X_disc_np = X_np[:, self.num_numeric_features:]\n",
        "\n",
        "        # Inverse transform numerical features\n",
        "        X_cont_inv = self.numeric_scaler.inverse_transform(X_cont_np)\n",
        "\n",
        "        # Convert softmax probabilities to categories for discrete features\n",
        "        X_disc_inv = []\n",
        "        start_idx = 0\n",
        "        for cat_feature, encoder in self.categorical_encoders.items():\n",
        "            end_idx = start_idx + len(encoder.categories_[0])\n",
        "            X_disc_inv.append(encoder.inverse_transform(X_disc_np[:, start_idx:end_idx]))\n",
        "            start_idx = end_idx\n",
        "\n",
        "        # Combine continuous and discrete data\n",
        "        X_generated = np.column_stack([X_cont_inv] + X_disc_inv)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        columns = list(self.numeric_features) + list(self.categorical_features)\n",
        "        \"\"\"\n",
        "\n",
        "        #X_generated_df = pd.DataFrame(X_generated, columns=columns)\n",
        "\n",
        "        #return X_generated_df\"\"\"\n",
        "\n",
        "        #X_generated_df = pd.DataFrame(X_generated, columns=columns)\n",
        "\n",
        "        #return X_generated_df\"\"\"\n",
        "\n",
        "    def impute(self, X):\n",
        "        X_imputed = X.copy()\n",
        "\n",
        "        print(f\"Original X shape: {X.shape}\")\n",
        "\n",
        "        # Preprocess the data\n",
        "        X_num = X_imputed[self.numeric_features].fillna(0)  # Fill NaN with 0 temporarily\n",
        "        X_cat = X_imputed[self.categorical_features].fillna('missing')  # Fill NaN with 'missing' temporarily\n",
        "\n",
        "        # Transform numeric features\n",
        "        X_num_processed = self.numeric_scaler.transform(X_num)\n",
        "\n",
        "        # Transform categorical features\n",
        "        X_cat_processed = np.column_stack([\n",
        "            self.categorical_encoders[feature].transform(X_cat[[feature]])\n",
        "            for feature in self.categorical_features\n",
        "        ])\n",
        "\n",
        "        X_processed = np.column_stack([X_num_processed, X_cat_processed])\n",
        "\n",
        "        print(f\"X_processed shape: {X_processed.shape}\")\n",
        "\n",
        "        # Create sequences\n",
        "        X_seq = self.create_sequences(X_processed, min(self.seq_length, X_processed.shape[0]))\n",
        "\n",
        "        print(f\"X_seq shape: {X_seq.shape}\")\n",
        "\n",
        "        X_cont = X_seq[:, :, :len(self.numeric_features)]\n",
        "        X_disc = X_seq[:, :, len(self.numeric_features):]\n",
        "\n",
        "        X_cont_tensor = torch.from_numpy(X_cont).float()\n",
        "        X_disc_tensor = torch.from_numpy(X_disc).float()\n",
        "\n",
        "        # Create a mask for missing values\n",
        "        mask = torch.tensor(X.isna().values, dtype=torch.bool)\n",
        "        print(f\"Original mask shape: {mask.shape}\")\n",
        "\n",
        "        # Adjust mask to match X_seq shape\n",
        "        adjusted_mask = mask.unsqueeze(1).repeat(1, X_seq.shape[1], 1)\n",
        "        adjusted_mask = adjusted_mask[:X_seq.shape[0], :, :]\n",
        "        print(f\"Adjusted mask shape: {adjusted_mask.shape}\")\n",
        "\n",
        "        # Expand mask to match X_imputed_tensor shape\n",
        "        expanded_mask = torch.zeros(X_seq.shape, dtype=torch.bool)\n",
        "        expanded_mask[:, :, :adjusted_mask.shape[2]] = adjusted_mask\n",
        "        print(f\"Expanded mask shape: {expanded_mask.shape}\")\n",
        "\n",
        "        # Initialize with random noise\n",
        "        X_imputed_tensor = torch.cat([X_cont_tensor, X_disc_tensor], dim=-1)\n",
        "        print(f\"X_imputed_tensor shape: {X_imputed_tensor.shape}\")\n",
        "        X_noise = torch.randn_like(X_imputed_tensor)\n",
        "\n",
        "        # Apply mask\n",
        "        X_imputed_tensor = torch.where(expanded_mask, X_noise, X_imputed_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for t in reversed(range(self.n_timesteps)):\n",
        "                X_imputed_tensor = self.reverse_process(X_imputed_tensor, torch.full((X_imputed_tensor.shape[0],), t))\n",
        "\n",
        "                # Keep original non-missing values\n",
        "                X_imputed_tensor = torch.where(expanded_mask, X_imputed_tensor, torch.cat([X_cont_tensor, X_disc_tensor], dim=-1))\n",
        "\n",
        "        # Convert back to numpy and original scale\n",
        "        X_imputed_np = X_imputed_tensor.squeeze(0).numpy()  # Remove the batch dimension\n",
        "        X_imputed_original = self.custom_inverse_transform(X_imputed_np)\n",
        "\n",
        "        # Create a DataFrame with imputed values\n",
        "        X_imputed_df = pd.DataFrame(X_imputed_original, columns=X.columns, index=X.index)\n",
        "\n",
        "        # Update only the missing values in the original DataFrame\n",
        "        for col in X.columns:\n",
        "            mask = X[col].isnull()\n",
        "            X_imputed.loc[mask, col] = X_imputed_df.loc[mask, col]\n",
        "\n",
        "        return X_imputed\n",
        "\n",
        "    def calculate_advanced_metrics(self, real_data, generated_data):\n",
        "        metrics = {}\n",
        "\n",
        "        # KS test for continuous features\n",
        "        for col in real_data.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            ks_statistic, p_value = ks_2samp(real_data[col], generated_data[col])\n",
        "            metrics[f'KS_statistic_{col}'] = ks_statistic\n",
        "            metrics[f'KS_p_value_{col}'] = p_value\n",
        "\n",
        "        # Chi-square test for categorical features\n",
        "        for col in real_data.select_dtypes(include=['object', 'category']).columns:\n",
        "            real_counts = real_data[col].value_counts()\n",
        "            gen_counts = generated_data[col].value_counts()\n",
        "            all_categories = set(real_counts.index) | set(gen_counts.index)\n",
        "            real_counts = real_counts.reindex(all_categories, fill_value=0)\n",
        "            gen_counts = gen_counts.reindex(all_categories, fill_value=0)\n",
        "            chi2, p_value, _, _ = chi2_contingency([real_counts, gen_counts])\n",
        "            metrics[f'Chi2_statistic_{col}'] = chi2\n",
        "            metrics[f'Chi2_p_value_{col}'] = p_value\n",
        "\n",
        "        # Categorical imbalance metric\n",
        "        for col in real_data.select_dtypes(include=['object', 'category']).columns:\n",
        "            real_prob = real_data[col].value_counts(normalize=True)\n",
        "            gen_prob = generated_data[col].value_counts(normalize=True)\n",
        "            imbalance = np.sum(np.abs(real_prob - gen_prob)) / 2  # Total Variation Distance\n",
        "            metrics[f'Categorical_imbalance_{col}'] = imbalance\n",
        "\n",
        "        # Jensen-Shannon Divergence for all features\n",
        "        for col in real_data.columns:\n",
        "            real_prob = real_data[col].value_counts(normalize=True)\n",
        "            gen_prob = generated_data[col].value_counts(normalize=True)\n",
        "            all_categories = set(real_prob.index) | set(gen_prob.index)\n",
        "            real_prob = real_prob.reindex(all_categories, fill_value=0)\n",
        "            gen_prob = gen_prob.reindex(all_categories, fill_value=0)\n",
        "            js_div = jensenshannon(real_prob, gen_prob)\n",
        "            metrics[f'JS_divergence_{col}'] = js_div\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def safe_column_name(self, column_name):\n",
        "          return re.sub(r'[^\\w\\s-]', '_', column_name)\n",
        "\n",
        "    def generate_comparison_plots(self, real_data, generated_data):\n",
        "        for col in real_data.columns:\n",
        "            safe_col = self.safe_column_name(col)\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            if real_data[col].dtype in ['float64', 'int64']:\n",
        "                sns.kdeplot(real_data[col], label='Real', shade=True)\n",
        "                sns.kdeplot(generated_data[col], label='Synthetic', shade=True)\n",
        "                plt.title(f'Distribution Comparison: {safe_col}')\n",
        "            else:\n",
        "                real_counts = real_data[col].value_counts(normalize=True)\n",
        "                gen_counts = generated_data[col].value_counts(normalize=True)\n",
        "                all_categories = set(real_counts.index) | set(gen_counts.index)\n",
        "                real_counts = real_counts.reindex(all_categories, fill_value=0)\n",
        "                gen_counts = gen_counts.reindex(all_categories, fill_value=0)\n",
        "                width = 0.35\n",
        "                x = range(len(all_categories))\n",
        "                plt.bar([i - width/2 for i in x], real_counts, width, label='Real')\n",
        "                plt.bar([i + width/2 for i in x], gen_counts, width, label='Synthetic')\n",
        "                plt.title(f'Categorical Distribution Comparison: {safe_col}')\n",
        "                plt.xticks(x, [self.safe_column_name(str(cat)) for cat in all_categories], rotation=45, ha='right')\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'distribution_comparison_{safe_col}.png')\n",
        "            plt.close()\n",
        "\n",
        "        # Correlation heatmap comparison\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "        sns.heatmap(real_data.corr(), ax=ax1, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "        ax1.set_title('Real Data Correlation')\n",
        "        sns.heatmap(generated_data.corr(), ax=ax2, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "        ax2.set_title('Synthetic Data Correlation')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('correlation_heatmap_comparison.png')\n",
        "        plt.close()\n",
        "\n",
        "        # Pairplot comparison (for a subset of features if there are many)\n",
        "        num_features = min(5, len(real_data.columns))\n",
        "        selected_features = real_data.columns[:num_features]\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "        sns.pairplot(real_data[selected_features], ax=ax1)\n",
        "        ax1.fig.suptitle('Real Data Pairplot', y=1.02)\n",
        "        sns.pairplot(generated_data[selected_features], ax=ax2)\n",
        "        ax2.fig.suptitle('Synthetic Data Pairplot', y=1.02)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('pairplot_comparison.png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "\n",
        "    def evaluate(self, X_real, X_generated):\n",
        "        # Transform real data\n",
        "        X_real_num = self.numeric_scaler.transform(X_real[self.numeric_features])\n",
        "        X_real_cat = np.column_stack([\n",
        "            self.categorical_encoders[feature].transform(X_real[[feature]])\n",
        "            for feature in self.categorical_features\n",
        "        ])\n",
        "        X_real_transformed = np.column_stack([X_real_num, X_real_cat])\n",
        "\n",
        "        # Transform generated data\n",
        "        X_generated_num = self.numeric_scaler.transform(X_generated[self.numeric_features])\n",
        "        X_generated_cat = np.column_stack([\n",
        "            self.categorical_encoders[feature].transform(X_generated[[feature]])\n",
        "            for feature in self.categorical_features\n",
        "        ])\n",
        "        X_generated_transformed = np.column_stack([X_generated_num, X_generated_cat])\n",
        "\n",
        "        X_real_flat = X_real_transformed.flatten()\n",
        "        X_generated_flat = X_generated_transformed.flatten()\n",
        "\n",
        "        w_distance = wasserstein_distance(X_real_flat, X_generated_flat)\n",
        "        print(f\"Wasserstein distance: {w_distance}\")\n",
        "\n",
        "        # Additional evaluation metrics\n",
        "        for col in self.numeric_features:\n",
        "            real_hist, _ = np.histogram(X_real[col], bins=30, density=True)\n",
        "            gen_hist, _ = np.histogram(X_generated[col], bins=30, density=True)\n",
        "            kl_div = scipy.stats.entropy(real_hist + 1e-10, gen_hist + 1e-10)  # Add small constant to avoid division by zero\n",
        "            print(f\"KL divergence for {col}: {kl_div}\")\n",
        "\n",
        "        for col in self.categorical_features:\n",
        "            real_dist = X_real[col].value_counts(normalize=True)\n",
        "            gen_dist = X_generated[col].value_counts(normalize=True)\n",
        "\n",
        "            # Ensure both distributions have the same categories\n",
        "            all_categories = set(real_dist.index) | set(gen_dist.index)\n",
        "            real_dist = real_dist.reindex(all_categories, fill_value=0)\n",
        "            gen_dist = gen_dist.reindex(all_categories, fill_value=0)\n",
        "\n",
        "            # Ensure the distributions sum to 1\n",
        "            real_dist = real_dist / real_dist.sum()\n",
        "            gen_dist = gen_dist / gen_dist.sum()\n",
        "\n",
        "            js_div = jensenshannon(real_dist, gen_dist)\n",
        "            print(f\"Jensen-Shannon divergence for {col}: {js_div}\")\n",
        "            # Plots pour les variables numériques\n",
        "            fig, axs = plt.subplots(len(self.numeric_features), 1, figsize=(10, 5*len(self.numeric_features)))\n",
        "            if len(self.numeric_features) == 1:\n",
        "                axs = [axs]  # Convertir en liste si un seul subplot\n",
        "            for i, col in enumerate(self.numeric_features):\n",
        "                clean_col = clean_string(col)\n",
        "                sns.histplot(X_real[col], kde=True, color='blue', alpha=0.5, ax=axs[i], label='Réel')\n",
        "                sns.histplot(X_generated[col], kde=True, color='red', alpha=0.5, ax=axs[i], label='Synthétique')\n",
        "                axs[i].set_title(f'Distribution de {clean_col}')\n",
        "                axs[i].legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('numeric_distributions.png')\n",
        "            plt.close()\n",
        "\n",
        "            # Plots pour les variables catégoriques\n",
        "            fig, axs = plt.subplots(len(self.categorical_features), 1, figsize=(10, 5*len(self.categorical_features)))\n",
        "            if len(self.categorical_features) == 1:\n",
        "                axs = [axs]  # Convertir en liste si un seul subplot\n",
        "            for i, col in enumerate(self.categorical_features):\n",
        "                clean_col = clean_string(col)\n",
        "                real_counts = X_real[col].value_counts(normalize=True)\n",
        "                gen_counts = X_generated[col].value_counts(normalize=True)\n",
        "\n",
        "                all_categories = list(set(real_counts.index) | set(gen_counts.index))\n",
        "                real_counts = real_counts.reindex(all_categories, fill_value=0)\n",
        "                gen_counts = gen_counts.reindex(all_categories, fill_value=0)\n",
        "\n",
        "                x = range(len(all_categories))\n",
        "                width = 0.35\n",
        "\n",
        "                axs[i].bar([i - width/2 for i in x], real_counts, width, label='Réel', alpha=0.5)\n",
        "                axs[i].bar([i + width/2 for i in x], gen_counts, width, label='Synthétique', alpha=0.5)\n",
        "                axs[i].set_title(f'Distribution de {clean_col}')\n",
        "                axs[i].set_xticks(x)\n",
        "                axs[i].set_xticklabels([clean_string(cat) for cat in all_categories], rotation=45, ha='right')\n",
        "                axs[i].legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('categorical_distributions.png')\n",
        "            plt.close()\n",
        "\n",
        "            # Heatmap des corrélations\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
        "            sns.heatmap(X_real[self.numeric_features].corr(), ax=ax1, cmap='coolwarm', annot=True)\n",
        "            ax1.set_title('Corrélations - Données Réelles')\n",
        "            sns.heatmap(X_generated[self.numeric_features].corr(), ax=ax2, cmap='coolwarm', annot=True)\n",
        "            ax2.set_title('Corrélations - Données Synthétiques')\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('correlation_heatmaps.png')\n",
        "            plt.close()\n",
        "\n",
        "    \"\"\"def calculate_advanced_metrics(self, X_real, X_generated):\n",
        "        metrics = {}\n",
        "\n",
        "        # KS test for continuous features\n",
        "        for col in X_real.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            try:\n",
        "                ks_statistic, p_value = ks_2samp(X_real[col], X_generated[col])\n",
        "                metrics[f'KS_statistic_{col}'] = ks_statistic\n",
        "                metrics[f'KS_p_value_{col}'] = p_value\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating KS test for column {col}: {str(e)}\")\n",
        "\n",
        "        # Chi-square test for categorical features\n",
        "        for col in X_real.select_dtypes(include=['object', 'category']).columns:\n",
        "            try:\n",
        "                real_counts = X_real[col].value_counts()\n",
        "                gen_counts = X_generated[col].value_counts()\n",
        "                all_categories = set(real_counts.index) | set(gen_counts.index)\n",
        "                real_counts = real_counts.reindex(all_categories, fill_value=0)\n",
        "                gen_counts = gen_counts.reindex(all_categories, fill_value=0)\n",
        "                chi2, p_value, _, _ = chi2_contingency([real_counts, gen_counts])\n",
        "                metrics[f'Chi2_statistic_{col}'] = chi2\n",
        "                metrics[f'Chi2_p_value_{col}'] = p_value\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating Chi-square test for column {col}: {str(e)}\")\n",
        "\n",
        "        # Categorical imbalance metric and Jensen-Shannon Divergence\n",
        "        for col in X_real.columns:\n",
        "            try:\n",
        "                real_prob = X_real[col].value_counts(normalize=True)\n",
        "                gen_prob = X_generated[col].value_counts(normalize=True)\n",
        "                all_categories = set(real_prob.index) | set(gen_prob.index)\n",
        "                real_prob = real_prob.reindex(all_categories, fill_value=0)\n",
        "                gen_prob = gen_prob.reindex(all_categories, fill_value=0)\n",
        "\n",
        "                imbalance = np.sum(np.abs(real_prob - gen_prob)) / 2\n",
        "                metrics[f'Categorical_imbalance_{col}'] = imbalance\n",
        "\n",
        "                js_div = jensenshannon(real_prob, gen_prob)\n",
        "                metrics[f'JS_divergence_{col}'] = js_div\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating imbalance and JS divergence for column {col}: {str(e)}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def utility_evaluation(self, X_real, y_real, X_generated):\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.linear_model import LogisticRegression\n",
        "        from sklearn.metrics import accuracy_score\n",
        "\n",
        "        # Split real data\n",
        "        X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(X_real, y_real, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Generate synthetic target for X_generated\n",
        "        y_generated = self.generate_synthetic_target(X_generated)\n",
        "\n",
        "        # Split generated data\n",
        "        X_gen_train, X_gen_test, y_gen_train, y_gen_test = train_test_split(X_generated, y_generated, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train and evaluate on real data\n",
        "        model_real = LogisticRegression()\n",
        "        model_real.fit(X_real_train, y_real_train)\n",
        "        real_accuracy = accuracy_score(y_real_test, model_real.predict(X_real_test))\n",
        "\n",
        "        # Train and evaluate on generated data\n",
        "        model_gen = LogisticRegression()\n",
        "        model_gen.fit(X_gen_train, y_gen_train)\n",
        "        gen_accuracy = accuracy_score(y_gen_test, model_gen.predict(X_gen_test))\n",
        "\n",
        "        return real_accuracy, gen_accuracy\n",
        "\n",
        "    def generate_synthetic_target(self, X_generated):\n",
        "        # Cette méthode doit être implémentée pour générer des cibles synthétiques\n",
        "        # correspondant à X_generated. Vous pouvez utiliser votre modèle de diffusion\n",
        "        # ou une autre méthode pour générer ces cibles.\n",
        "        # Pour l'instant, nous allons simplement générer des valeurs aléatoires\n",
        "        return np.random.randint(0, 2, size=len(X_generated))\"\"\"\n",
        "    \"\"\"\n",
        "    def add_noise(self, x, t):\n",
        "        noise = torch.randn_like(x)\n",
        "        sqrt_alphas_cumprod_t = torch.sqrt(self.alphas_cumprod[t]).unsqueeze(-1).unsqueeze(-1)\n",
        "        sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1 - self.alphas_cumprod[t]).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        return sqrt_alphas_cumprod_t * x + sqrt_one_minus_alphas_cumprod_t * noise\"\"\"\n",
        "    def add_noise(self, x, t):\n",
        "        noise = torch.randn_like(x)\n",
        "        sqrt_alphas_cumprod_t = torch.sqrt(self.alphas_cumprod[t]).view(-1, 1, 1)\n",
        "        sqrt_one_minus_alphas_cumprod_t = torch.sqrt(1 - self.alphas_cumprod[t]).view(-1, 1, 1)\n",
        "        return sqrt_alphas_cumprod_t * x + sqrt_one_minus_alphas_cumprod_t * noise\n",
        "\n",
        "    def custom_inverse_transform(self, X):\n",
        "        num_features = len(self.numeric_features)\n",
        "        X_num = X[:, :num_features]\n",
        "        X_cat = X[:, num_features:]\n",
        "\n",
        "        # Inverse transform numerical features\n",
        "        X_num_inv = self.numeric_scaler.inverse_transform(X_num)\n",
        "\n",
        "        # Inverse transform categorical features\n",
        "        X_cat_inv = []\n",
        "        start_idx = 0\n",
        "        for cat_feature, encoder in self.categorical_encoders.items():\n",
        "            end_idx = start_idx + len(encoder.categories_[0])\n",
        "            X_cat_inv.append(encoder.inverse_transform(X_cat[:, start_idx:end_idx]))\n",
        "            start_idx = end_idx\n",
        "\n",
        "        # Combine numerical and categorical features\n",
        "        X_combined = np.column_stack([X_num_inv] + X_cat_inv)\n",
        "\n",
        "        return X_combined\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1):\n",
        "        def sample_gumbel(shape, eps=1e-10, device=None):\n",
        "            U = torch.rand(shape, device=device)\n",
        "            return -torch.log(-torch.log(U + eps) + eps)\n",
        "\n",
        "        device = logits.device\n",
        "        gumbels = sample_gumbel(logits.shape, eps=eps, device=device)\n",
        "        gumbels = (logits + gumbels) / tau\n",
        "        y_soft = gumbels.softmax(dim)\n",
        "\n",
        "        if hard:\n",
        "            index = y_soft.max(dim, keepdim=True)[1]\n",
        "            y_hard = torch.zeros_like(logits, device=device).scatter_(dim, index, 1.0)\n",
        "            ret = y_hard - y_soft.detach() + y_soft\n",
        "        else:\n",
        "            ret = y_soft\n",
        "        return ret\n",
        "\n"
      ],
      "metadata": {
        "id": "GVghh0xY5AHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    torch.autograd.set_detect_anomaly(True)\n",
        "    torch.autograd.profiler.profile(enabled=True)\n",
        "    torch.autograd.profiler.emit_nvtx(enabled=True)\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "\n",
        "    data_path = \"/notebooks/data.csv\"\n",
        "    seq_length = 30  # Define the sequence length\n",
        "    dt = pd.read_csv(data_path)\n",
        "    model = FinDiffusionPlus(n_timesteps=200, n_noise=200, learning_rate=0.001, seq_length=seq_length)\n",
        "    X, y = model.preprocess_data(data_path)\n",
        "    # Split the data\n",
        "    train_size = int(0.8 * len(X))\n",
        "    X_train, X_test = X[:train_size], X[train_size:]\n",
        "    y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "    # Train the model\n",
        "    model.train(X_train, y_train)\n",
        "\n",
        "    # Generate synthetic data\n",
        "    num_synthetic_samples = 1000\n",
        "    synthetic_data = model.generate(num_synthetic_samples)\n",
        "\n",
        "    print(f\"Generated {num_synthetic_samples} synthetic samples.\")\n",
        "    print(synthetic_data.head())\n",
        "\n",
        "    # Evaluate the generated data\n",
        "    X_test_df = pd.DataFrame(model.custom_inverse_transform(X_test[:, -1, :]),\n",
        "                             columns=list(model.numeric_features) + list(model.categorical_features))\n",
        "    model.evaluate(X_test_df, synthetic_data)\n",
        "\n",
        "    plot_numeric_distributions(model, synthetic_data)\n",
        "    plot_categorical_distributions(model, synthetic_data)\n",
        "\n",
        "\n",
        "    # Export synthetic data to CSV\n",
        "    synthetic_data.to_csv(\"res.csv\", index=False)\n",
        "    print(\"\\nSynthetic data exported to res.csv\")\n",
        "    \"\"\"\n",
        "    # Generate plots\n",
        "    # 1. Distribution of numerical features\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "    for i, feature in enumerate(model.numeric_features):\n",
        "        sns.histplot(synthetic_data[feature], ax=axes[i//4, i%4], kde=True)\n",
        "        axes[i//4, i%4].set_title(feature)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"numerical_distributions.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # 2. Countplot of categorical features\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
        "    for i, feature in enumerate(model.categorical_features):\n",
        "        sns.countplot(data=synthetic_data, x=feature, ax=axes[i//4, i%4])\n",
        "        axes[i//4, i%4].set_title(feature)\n",
        "        axes[i//4, i%4].tick_params(axis='x', rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"categorical_counts.png\")\n",
        "    plt.close()\"\"\"\n",
        "\n",
        "    # 3. Correlation heatmap of numerical features\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(synthetic_data[model.numeric_features].corr(), annot=True, cmap='coolwarm')\n",
        "    plt.title(\"Correlation Heatmap of Numerical Features\")\n",
        "    plt.savefig(\"correlation_heatmap_beta.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # 4. Pairplot of numerical features\n",
        "    sns.pairplot(synthetic_data[model.numeric_features])\n",
        "    plt.savefig(\"pairplot.png\")\n",
        "    plt.close()\n",
        "\n",
        "    #Scatter plot\n",
        "\n",
        "    continuous_feature1 = 'age'\n",
        "    continuous_feature2 = 'Mutual_Funds'\n",
        "    categorical_feature = 'gender'\n",
        "\n",
        "    \"\"\"\n",
        "    # Generate synthetic data with different guidance strengths\n",
        "    guidance_strengths = [0.0, 1.0, 2.0, 3.0]\n",
        "    for strength in guidance_strengths:\n",
        "        synthetic_data = model.generate(num_synthetic_samples, guidance_strength=strength)\n",
        "\n",
        "        # Create scatter plot\n",
        "        model.plot_scatter(X_test_df, synthetic_data, continuous_feature1, continuous_feature2, categorical_feature, strength)\n",
        "\n",
        "        print(f\"Generated scatter plot for guidance strength {strength}\")\n",
        "\n",
        "    print(\"\\nPlots generated and saved as PNG files.\")\"\"\"\n",
        "\"\"\"\n",
        "    # Imputation example\n",
        "    X_with_missing = X_test_df.copy()\n",
        "    X_with_missing.iloc[np.random.rand(*X_with_missing.shape) < 0.2] == np.nan\n",
        "    #X_imputed = model.impute(X_with_missing)\n",
        "    print(\"\\nImputation example:\")\n",
        "    print(X_imputed.head())\"\"\""
      ],
      "metadata": {
        "id": "8vgyORnI5BPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "real_data = pd.read_csv(\"/notebooks/data.csv\")\n",
        "def clean_column_name(name):\n",
        "    return re.sub(r'[^\\w\\s-]', '_', str(name))\n",
        "\n",
        "def plot_numeric_comparisons(model, real_data, synthetic_data):\n",
        "    num_features = len(model.numeric_features)\n",
        "    if num_features == 0:\n",
        "        print(\"Aucune caractéristique numérique à afficher.\")\n",
        "        return\n",
        "\n",
        "    num_cols = min(3, num_features)\n",
        "    num_rows = (num_features - 1) // num_cols + 1\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(6*num_cols, 5*num_rows))\n",
        "    if num_features == 1:\n",
        "        axes = np.array([[axes]])\n",
        "    elif num_rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for i, feature in enumerate(model.numeric_features):\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "        clean_feature = clean_column_name(feature)\n",
        "\n",
        "        sns.histplot(real_data[feature], color=\"blue\", label=\"Réel\", kde=True,\n",
        "                     ax=axes[row, col], alpha=0.5)\n",
        "        sns.histplot(synthetic_data[feature], color=\"red\", label=\"Synthétique\", kde=True,\n",
        "                     ax=axes[row, col], alpha=0.5)\n",
        "\n",
        "        axes[row, col].set_title(f\"Distribution de {clean_feature}\")\n",
        "        axes[row, col].legend()\n",
        "\n",
        "    for i in range(num_features, num_rows * num_cols):\n",
        "        fig.delaxes(axes[i // num_cols, i % num_cols])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"numeric_comparisons_beta.png\")\n",
        "    plt.close()\n",
        "    print(\"Le graphique des comparaisons numériques a été sauvegardé sous 'numeric_comparisons.png'\")\n",
        "\n",
        "def plot_categorical_comparisons(model, real_data, synthetic_data):\n",
        "    cat_features = model.categorical_features\n",
        "    if len(cat_features) == 0:\n",
        "        print(\"Aucune caractéristique catégorique à afficher.\")\n",
        "        return\n",
        "\n",
        "    num_cols = min(3, len(cat_features))\n",
        "    num_rows = (len(cat_features) - 1) // num_cols + 1\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(6*num_cols, 5*num_rows))\n",
        "    if len(cat_features) == 1:\n",
        "        axes = np.array([[axes]])\n",
        "    elif num_rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for i, feature in enumerate(cat_features):\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "        clean_feature = clean_column_name(feature)\n",
        "\n",
        "        real_counts = real_data[feature].value_counts(normalize=True)\n",
        "        synth_counts = synthetic_data[feature].value_counts(normalize=True)\n",
        "\n",
        "        # Assurer que les deux séries ont les mêmes index\n",
        "        all_categories = sorted(set(real_counts.index) | set(synth_counts.index))\n",
        "        real_counts = real_counts.reindex(all_categories, fill_value=0)\n",
        "        synth_counts = synth_counts.reindex(all_categories, fill_value=0)\n",
        "\n",
        "        x = np.arange(len(all_categories))\n",
        "        width = 0.35\n",
        "\n",
        "        axes[row, col].bar(x - width/2, real_counts, width, label='Réel', alpha=0.7)\n",
        "        axes[row, col].bar(x + width/2, synth_counts, width, label='Synthétique', alpha=0.7)\n",
        "\n",
        "        axes[row, col].set_title(f\"Distribution de {clean_feature}\")\n",
        "        axes[row, col].set_xticks(x)\n",
        "        axes[row, col].set_xticklabels([clean_column_name(cat) for cat in all_categories], rotation=45, ha='right')\n",
        "        axes[row, col].legend()\n",
        "\n",
        "    for i in range(len(cat_features), num_rows * num_cols):\n",
        "        fig.delaxes(axes[i // num_cols, i % num_cols])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"categorical_comparisons_beta.png\")\n",
        "    plt.close()\n",
        "    print(\"Le graphique des comparaisons catégoriques a été sauvegardé sous 'categorical_comparisons.png'\")\n",
        "\n",
        "# Utilisation\n",
        "plot_numeric_comparisons(model, real_data, synthetic_data)\n",
        "plot_categorical_comparisons(model, real_data, synthetic_data)"
      ],
      "metadata": {
        "id": "ksYaMwTR5CHq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}